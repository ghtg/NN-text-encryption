import tensorflow as tf
import numpy as np
import pandas as pd
import os

# ะะฐัะฐะผะตััั
MAX_SEQ_LENGTH = 10
CHARACTER_SET = "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ1234567890-=+_!@#$%^&*()|><โค๏ธโจโ๐ฅ๐๐๐โญ๐ญุุุุกุขุฃูโโโโโโโโโโโโโโโโโโโโโซโฌโญโฎโฏโฐโฑโฒโณโดโตโธโพโฟะฐะฑะฒะณะดะตัะถะทะธะนะบะปะผะฝะพะฟััััััััััััััััะะะะะะะะะะะะะะะะะะะกะขะฃะคะฅะฆะงะจะฉะชะซะฌะญะฎะฏ"
NUM_CLASSES = len(CHARACTER_SET)
EMBEDDING_DIM = 16
HIDDEN_UNITS = 64
LEARNING_RATE = 0.001
EPOCHS = 100

def preprocess_data(filename):
    df = pd.read_csv(filename, header=None)
    decrypt_texts = df[0].values
    encrypt_texts = df[1].values
    
    # ะกะพะทะดะฐะฝะธะต ัะปะพะฒะฐัะตะน ะดะปั ะฟัะตะพะฑัะฐะทะพะฒะฐะฝะธั ัะธะผะฒะพะปะพะฒ ะฒ ะธะฝะดะตะบัั
    char_to_idx = {char: idx for idx, char in enumerate(CHARACTER_SET)}
    idx_to_char = {idx: char for idx, char in enumerate(CHARACTER_SET)}
    
    def text_to_sequence(text, max_length):
        seq = [char_to_idx.get(c, 0) for c in text]  # 0 ะดะปั ะฝะตะธะทะฒะตััะฝัั ัะธะผะฒะพะปะพะฒ
        return seq + [0] * (max_length - len(seq))  # ะะพะฟะพะปะฝะตะฝะธะต ะดะพ max_length
    
    x_data = np.array([text_to_sequence(t, MAX_SEQ_LENGTH) for t in decrypt_texts])
    y_data = np.array([text_to_sequence(t, MAX_SEQ_LENGTH) for t in encrypt_texts])
    
    return x_data, y_data, idx_to_char

def create_models():
    # Encoder model
    encoder = tf.keras.Sequential([
        tf.keras.layers.Input(shape=(MAX_SEQ_LENGTH,)),
        tf.keras.layers.Embedding(input_dim=NUM_CLASSES, output_dim=EMBEDDING_DIM),
        tf.keras.layers.Conv1D(filters=128, kernel_size=3, activation='relu', padding='same'),
        tf.keras.layers.MaxPooling1D(pool_size=1, padding='same'),
        
        # ะะตัะฒัะน ัะปะพะน LSTM
        tf.keras.layers.LSTM(HIDDEN_UNITS, return_sequences=True),
        
        # ะะพะฑะฐะฒะปัะตะผ ะฒัะพัะพะน ัะปะพะน LSTM
        tf.keras.layers.LSTM(HIDDEN_UNITS, return_sequences=True),
        
        tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(NUM_CLASSES, activation='softmax'))
    ])
    
    # Decoder model
    decoder = tf.keras.Sequential([
        tf.keras.layers.Input(shape=(MAX_SEQ_LENGTH,)),
        tf.keras.layers.Embedding(input_dim=NUM_CLASSES, output_dim=EMBEDDING_DIM),
        tf.keras.layers.Conv1D(filters=128, kernel_size=3, activation='relu', padding='same'),
        tf.keras.layers.MaxPooling1D(pool_size=1, padding='same'),
        
        # ะะตัะฒัะน ัะปะพะน LSTM
        tf.keras.layers.LSTM(HIDDEN_UNITS, return_sequences=True),
        
        # ะะพะฑะฐะฒะปัะตะผ ะฒัะพัะพะน ัะปะพะน LSTM
        tf.keras.layers.LSTM(HIDDEN_UNITS, return_sequences=True),
        
        tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(NUM_CLASSES, activation='softmax'))
    ])
    
    return encoder, decoder

def compile_model(model):
    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])

def learn(filename, epochs):
    x_data, y_data, idx_to_char = preprocess_data(filename)
    
    # ะกะพะทะดะฐะฝะธะต ะผะพะดะตะปะตะน, ะตัะปะธ ะพะฝะธ ะฝะต ะทะฐะณััะถะตะฝั
    encoder, decoder = create_models()
    
    # ะัะพะฒะตัะบะฐ ะฝะฐะปะธัะธั ัะพััะฐะฝะตะฝะฝะพะน ะผะพะดะตะปะธ ะธ ะทะฐะณััะทะบะฐ ะฒะตัะพะฒ
    if os.path.exists('encoder_model.keras'):
        encoder = tf.keras.models.load_model('encoder_model.keras', compile=False)
        # ะะตัะตัะพะทะดะฐะตะผ ะพะฟัะธะผะธะทะฐัะพั ะธ ะบะพะผะฟะธะปะธััะตะผ ะผะพะดะตะปั ะทะฐะฝะพะฒะพ
        encoder.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE), 
                        loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    else:
        compile_model(encoder)  # ะะพะผะฟะธะปะธััะตะผ ะฝะพะฒัั ะผะพะดะตะปั, ะตัะปะธ ะฝะต ะทะฐะณััะถะตะฝะฐ
    
    if os.path.exists('decoder_model.keras'):
        decoder = tf.keras.models.load_model('decoder_model.keras', compile=False)
        # ะะตัะตัะพะทะดะฐะตะผ ะพะฟัะธะผะธะทะฐัะพั ะธ ะบะพะผะฟะธะปะธััะตะผ ะผะพะดะตะปั ะทะฐะฝะพะฒะพ
        decoder.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE), 
                        loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    else:
        compile_model(decoder)  # ะะพะผะฟะธะปะธััะตะผ ะฝะพะฒัั ะผะพะดะตะปั, ะตัะปะธ ะฝะต ะทะฐะณััะถะตะฝะฐ
    
    for epoch in range(epochs):
        # ะะฑััะตะฝะธะต ัะธััะฐัะพัะฐ (encoder)
        encoder.fit(x_data, np.expand_dims(y_data, -1), epochs=1, batch_size=64)
        
        # ะัะพะณะฝะพะทะธัะพะฒะฐะฝะธะต ะทะฐัะธััะพะฒะฐะฝะฝะพะณะพ ัะตะบััะฐ
        encoder_predictions = encoder.predict(x_data)
        
        # ะะฑััะตะฝะธะต ะดะตัะธััะฐัะพัะฐ (decoder)
        decoder.fit(np.expand_dims(y_data, -1), x_data, epochs=1, batch_size=64)
        
        # ะกะพััะฐะฝะตะฝะธะต ะผะพะดะตะปะตะน ะบะฐะถะดัะต 100 ัะฟะพั
        if (epoch + 1) % 100 == 0:
            encoder.save('encoder_model.keras')
            decoder.save('decoder_model.keras')
            print(f'Epoch {epoch + 1}/{epochs} - Models saved.')
    
    # ะคะธะฝะฐะปัะฝะพะต ัะพััะฐะฝะตะฝะธะต ะผะพะดะตะปะตะน
    encoder.save('encoder_model.keras')
    decoder.save('decoder_model.keras')
    
    return idx_to_char


def encrypt(text, encoder, idx_to_char):
    char_to_idx = {char: idx for idx, char in enumerate(CHARACTER_SET)}
    seq = np.array([char_to_idx.get(c, 0) for c in text]).reshape(1, -1)
    pred = encoder.predict(seq)
    pred_seq = np.argmax(pred, axis=-1).flatten()
    encrypted_text = ''.join([idx_to_char.get(idx, '?') for idx in pred_seq])
    return encrypted_text.strip()

def decrypt(text, decoder, idx_to_char):
    char_to_idx = {char: idx for idx, char in enumerate(CHARACTER_SET)}
    seq = np.array([char_to_idx.get(c, 0) for c in text]).reshape(1, -1)
    pred = decoder.predict(seq)
    pred_seq = np.argmax(pred, axis=-1).flatten()
    decrypted_text = ''.join([idx_to_char.get(idx, '?') for idx in pred_seq])
    return decrypted_text.strip()

def load_dataset(filename):
    """ะะฐะณััะถะฐะตั ะดะฐัะฐัะตั ะธ ะฒะพะทะฒัะฐัะฐะตั ัะปะพะฒะฐัั ะดะปั ะฑััััะพะณะพ ะฟะพะธัะบะฐ."""
    df = pd.read_csv(filename, header=None)
    dataset = {row[0]: row[1] for _, row in df.iterrows()}  # {'ัะฐััะธััะพะฒะฐะฝะฝัะน': 'ะทะฐัะธััะพะฒะฐะฝะฝัะน'}
    return dataset

if __name__ == "__main__":
    # ะะฐะณััะทะบะฐ ะดะฐัะฐัะตัะฐ ะดะปั ะฟัะพะฒะตัะบะธ
    dataset = load_dataset('dataset.csv')
    
    # ะะฑััะตะฝะธะต ะผะพะดะตะปะตะน
    idx_to_char = learn('dataset.csv', EPOCHS)
    
    # ะะฐะณััะทะบะฐ ะพะฑััะตะฝะฝัั ะผะพะดะตะปะตะน
    encoder_model = tf.keras.models.load_model('encoder_model.keras')
    decoder_model = tf.keras.models.load_model('decoder_model.keras')

    # ะัะธะผะตั ัะธััะพะฒะฐะฝะธั ะธ ัะฐััะธััะพะฒะฐะฝะธั
    test_texts = ['ghtg_crazy','TowerBattl','cryptoscam','abcdefghij','vsemprivet','Vsem_Prive','kOmfOrtIkI','LokoMarina','1234567890','0NoskiMoi0','crackedboo','CodeMaster','HelloWorld','funny_game','skyHigh202','alphaOmega','RoboKnight','DragonSlay','SuperHero+','crazy_logi','TowerFall1','StealthNin','CyberPunk_','SpaceInvad','NeonDreame','VoidWalker','LaserKnigh','NochDvoem','vsEmPRIVET','zdravstvui','NochDvoyem','nochkadvoy','segodnya!!','zdravtiLyu','!RobloxBAN','scri!pters','cryptissas','cryptcscam','1231231231','Sooooooooo','Rak1NaDiva','Encryption','ShreksOuse','FRIENDSHIP','I_HATE_YOU','I_LOVE_YOU','8937273625','creATE_MAC','ok','skies','zdorova!','zdrasti','zdraste','privetikvs','zdrast','zdravst','zaebal','ZavaliEbal','Adventure','Basketball','Curriculum','Democracy','Diligently','Electronic','Expansions','Friendship','Generation','Geography','Historical','Innovation','Journalism','Leadership','Literature','Navigation','Optimistic','Perception','Publishing','Revolution','Reflection','Sensations','Speculator','Superhuman','Television','Terminolog','Translatio','Vegetarian','Volleyball','Watermelon','-=+_!@#$%^','&*()|><โค๏ธโจ','โโโโโโโโโโ','โโโโโโโโโโ','โโโโโซโฌโญโฎโฏโฐ','โฐโฑโฒโณโดโตโธโพโฟ','happy_day','zvezdochka','ljubov_pri','naxodka!','zdraste','privetik','super_bob','ne_vernus!','ะบัะฐัะฐะฒะฐ123','ะฟัะธะฒะตัโค๏ธ','ะถะธะทะฝั_ะฑะพะปั','ััะฐััะปะธะฒัะธ','ัััะฑะฐ_ัะฐัะด','ะดะฐะฒะฐะน_ะฟะพะณะพ','ะพะณะพะฝั!!!','ะฝะต_ัะดะฐะผัั','ะฟะพะปะฝัะน_ัะฐ','ะทะฒะตะทะดั_ะฝะฐ_','ะฒะปัะฑะปัะฝะฝัะน','ะฝะฐััะฝะฐั_ั','ะัะฑะธะผััััะน','GENESIS182','Genesis211','52SquadGo!','ะผะฐะผะฐ']
    
    # ะัะบััะฒะฐะตะผ ัะฐะนะป ะฒ ัะตะถะธะผะต ะดะพะฑะฐะฒะปะตะฝะธั
    errors = 0

    # ะัะบััะฒะฐะตะผ ัะฐะนะป ะฒ ัะตะถะธะผะต ะดะพะฑะฐะฒะปะตะฝะธั ั ัะบะฐะทะฐะฝะธะตะผ ะบะพะดะธัะพะฒะบะธ utf-8
    with open('errors_log.txt', 'a', encoding='utf-8') as file:
        for text in test_texts:
            encrypted = encrypt(text, encoder_model, idx_to_char)
            decrypted = decrypt(encrypted, decoder_model, idx_to_char)
            
            # ะัะพะฒะตัะบะฐ, ะตััั ะปะธ ะดะฐะฝะฝัะต ะฒ ะดะฐัะฐัะตัะต
            in_dataset = text in dataset
            if in_dataset:
                expected_encrypted = dataset[text]
                is_encrypted_correct = (encrypted == expected_encrypted)
                is_decrypted_correct = (decrypted == text)
                
                if not is_encrypted_correct:
                    # ะะฐะฟะธััะฒะฐะตะผ ะดะฐะฝะฝัะต ะฒ ัะฐะนะป, ะตัะปะธ ัะฐััะธััะพะฒะบะฐ ะฝะตะฒะตัะฝะฐ
                    file.write(f'{text},{encrypted},{decrypted}\n')
                    file.write(f'In Dataset: Yes, Expected Encrypted: {expected_encrypted}\n')
                    file.write(f'Encryption Correct: {is_encrypted_correct}, Decryption Correct: {is_decrypted_correct}\n')
                    errors += 1
            else:
                # ะะฐะฟะธััะฒะฐะตะผ ะดะฐะฝะฝัะต ะฒ ัะฐะนะป, ะตัะปะธ ัะตะบัั ะพััััััะฒัะตั ะฒ ะดะฐัะฐัะตัะต
                file.write(f'{text},{encrypted}\n')
        
        # ะะฐะฟะธััะฒะฐะตะผ ะบะพะปะธัะตััะฒะพ ะพัะธะฑะพะบ ะฒ ัะฐะนะป
        file.write(f'Errors: {errors}\n')
